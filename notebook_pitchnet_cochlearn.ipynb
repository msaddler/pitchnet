{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/python-packages/msutil')\n",
    "import util_figures_cnn\n",
    "import util_stimuli\n",
    "import util_misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_brain_arch = '/saved_models/arch_search_v02_topN/f0_label_192/arch_0302/brain_arch.json'\n",
    "with open(fn_brain_arch, 'r') as f:\n",
    "    list_brain_arch = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:385: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:56: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:76: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:80: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /om2/user/msaddler/pitchnet/ibmHearingAid/multi_gpu/functions_brain_network.py:84: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 100, 1000, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "output_tensor, nets = functions_brain_network.make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tfnnresample] interpreting `tensor_input.shape` as [batch, freq, time, channels]\n",
      "[tfnnresample] using up=1 rather than up=5 for nnresample_poly_filter\n",
      "[tfnnresample] using down=4 rather than down=8 for nnresample_poly_filter\n",
      "[tfnnresample] using window_length=8000 for nnresample_poly_filter\n",
      "[tfnnresample] using cutoff frequency near 4000.0 Hz for anti-aliasing lowpass filter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'coch_relu_1:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       " {'coch_conv_0': <tf.Tensor 'coch_conv_0/BiasAdd:0' shape=(1, 1, 1600, 100) dtype=float32>,\n",
       "  'coch_relu_0': <tf.Tensor 'coch_relu_0:0' shape=(1, 100, 1600, 1) dtype=float32>,\n",
       "  'coch_relu_1': <tf.Tensor 'coch_relu_1:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_slice_0': <tf.Tensor 'coch_slice_0:0' shape=(1, 1, 2400, 1) dtype=float32>,\n",
       "  'coch_tfnnresample_0': <tf.Tensor 'Conv2D:0' shape=(1, 100, 1000, 1) dtype=float32>,\n",
       "  'coch_transpose_0': <tf.Tensor 'coch_transpose_0:0' shape=(1, 100, 1600, 1) dtype=float32>})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_shape = [1, 1, 4800, 1]\n",
    "input_tensor = tf.placeholder(tf.float32, shape=input_shape, name='input_tensor')\n",
    "\n",
    "list_brain_arch_tmp = [\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_slice_0',\n",
    "            'begin': [0, 0, 2160, 0],\n",
    "            'size': [-1, -1, 2400, -1],\n",
    "        },\n",
    "        'layer_type': 'tf.slice'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'activation': None,\n",
    "            'dilation_rate': [1, 1],\n",
    "            'filters': 100,\n",
    "            'kernel_size': [1, 801],\n",
    "            'name': 'coch_conv_0',\n",
    "            'padding': 'VALID',\n",
    "            'strides': [1, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.layers.conv2d'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_transpose_0',\n",
    "            'perm': [0, 3, 2, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.transpose'\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_0\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_tfnnresample_0\",\n",
    "            \"sr_input\": 32e3,\n",
    "            \"sr_output\": 20e3,\n",
    "            \"kwargs_nnresample_poly_filter\": {\n",
    "                \"down\": 4,\n",
    "                \"up\": 1\n",
    "            },\n",
    "        },\n",
    "        \"layer_type\": \"tfnnresample\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_1\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# list_brain_arch_tmp = list_brain_arch_tmp + list_brain_arch\n",
    "\n",
    "import importlib\n",
    "importlib.reload(functions_brain_network)\n",
    "\n",
    "output_tensor, nets = functions_brain_network.make_brain_net(\n",
    "    input_tensor,\n",
    "    {'f0_label': 700},\n",
    "    list_brain_arch_tmp)\n",
    "\n",
    "output_tensor, nets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.4471 80.4471\n",
      "0.07\n",
      "2240 -320\n",
      "50.397247\n"
     ]
    }
   ],
   "source": [
    "regex_fn = '/om/scratch/*/msaddler/data_pitchnet/PND_v08/noise_TLAS_snr_neg10pos10/PND_*.hdf5'\n",
    "list_fn = glob.glob(regex_fn)\n",
    "fn = list_fn[0]\n",
    "# for k in util_misc.get_hdf5_dataset_key_list(fn):\n",
    "#     print(k)\n",
    "\n",
    "with h5py.File(fn, 'r') as f:\n",
    "    IDX = -50\n",
    "    idx0 = f['nopad_start_index'][IDX] - f['segment_start_index'][IDX]\n",
    "    idx1 = f['nopad_end_index'][IDX] - f['segment_end_index'][IDX]\n",
    "    \n",
    "    print(f['f0'][IDX], f['nopad_f0_mean'][IDX])\n",
    "    print(f['stimuli/signal_in_noise'][IDX, idx0:idx1].shape[0] / f['sr'][0])\n",
    "    print(idx0, idx1)\n",
    "    \n",
    "    print(f['stimuli/signal_in_noise_dBSPL'][IDX])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### /om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (72600, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (83391, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (83304, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (24576, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (36864, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (73728, 4800), type \"<f4\">\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim.hdf5\n",
      "### /om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim_waveform.hdf5\n",
      "<HDF5 dataset \"signal_in_noise\": shape (134328, 4800), type \"<f4\">\n"
     ]
    }
   ],
   "source": [
    "list_fn =[\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/lowharm_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/mooremoore2003/freqshifted_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/moore1985/mistunedharm_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/oxenham2004/transposedtones_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/shackcarl1994/altphase_v01/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/exact_v00/stim.hdf5',\n",
    "    '/om/user/msaddler/data_pitchnet/bernox2005/exact_v01/stim.hdf5',\n",
    "]\n",
    "for fn in list_fn:\n",
    "    list_k = util_misc.get_hdf5_dataset_key_list(fn)\n",
    "    fn_new = fn.replace('.hdf5', '_waveform.hdf5')\n",
    "    with h5py.File(fn, 'r') as f:\n",
    "        print('###', fn)\n",
    "        print('###', fn_new)\n",
    "        list_candidate_signal_k = [k for k in list_k if f[k].shape[-1] == 4800]\n",
    "        list_other_k = [k for k in list_k if not f[k].shape[-1] == 4800]\n",
    "        if len(list_candidate_signal_k) > 1:\n",
    "            list_candidate_signal_k = [k for k in list_candidate_signal_k if 'noise' in k]\n",
    "        assert len(list_candidate_signal_k) == 1\n",
    "        \n",
    "        assert not fn_new == fn\n",
    "#         with h5py.File(fn_new, 'w') as f_new:\n",
    "#             for k in list_other_k:\n",
    "#                 f_new.create_dataset(k, data=f[k][:])\n",
    "#             f_new.create_dataset('stimuli/signal_in_noise', data=f[list_candidate_signal_k[0]][:])\n",
    "#             print(f_new['stimuli/signal_in_noise'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0083/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0083/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0154/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0154/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0190/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0190/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0191/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0191/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0286/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0286/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0288/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0288/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0302/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0302/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0335/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0335/config.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0338/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0338/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Copying files: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Renaming in CONFIG: /saved_models/arch_search_v02_topN/sr20000_cf100_species002_spont070_BW10eN1_IHC3000Hz_IHC7order/arch_0346/brain_arch.json --> /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/brain_arch.json\n",
      "Pre-existing config file found: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/config.json\n",
      "config_dict similarity check is ignoring: ['BRAIN_PARAMS/config', 'BRAIN_PARAMS/save_arch_path']\n",
      "Successfully (over)wrote config file: /saved_models/arch_search_v02_topN/cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10/arch_0346/config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import glob\n",
    "import copy\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append('/code_location/multi_gpu')\n",
    "import functions_parameter_handling\n",
    "importlib.reload(functions_parameter_handling)\n",
    "\n",
    "list_brain_arch_prepend = [\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_slice_0',\n",
    "            'begin': [0, 0, 2160, 0],\n",
    "            'size': [-1, -1, 2400, -1],\n",
    "        },\n",
    "        'layer_type': 'tf.slice'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'activation': None,\n",
    "            'dilation_rate': [1, 1],\n",
    "            'filters': 100,\n",
    "            'kernel_size': [1, 801],\n",
    "            'name': 'coch_conv_0',\n",
    "            'padding': 'VALID',\n",
    "            'strides': [1, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.layers.conv2d'\n",
    "    },\n",
    "    {\n",
    "        'args': {\n",
    "            'name': 'coch_transpose_0',\n",
    "            'perm': [0, 3, 2, 1]\n",
    "        },\n",
    "        'layer_type': 'tf.transpose'\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_0\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_tfnnresample_0\",\n",
    "            \"sr_input\": 32e3,\n",
    "            \"sr_output\": 20e3,\n",
    "            \"kwargs_nnresample_poly_filter\": {\n",
    "                \"down\": 8,\n",
    "                \"up\": 5,\n",
    "                \"window_length\": 161\n",
    "            },\n",
    "        },\n",
    "        \"layer_type\": \"tfnnresample\"\n",
    "    },\n",
    "    {\n",
    "        \"args\": {\n",
    "            \"name\": \"coch_relu_1\"\n",
    "        },\n",
    "        \"layer_type\": \"tf.nn.relu\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "regex_src_dir = '/saved_models/arch_search_v02_topN/TEMPLATE/arch_0???'\n",
    "list_src_dir = glob.glob(regex_src_dir)\n",
    "\n",
    "for src_dir in list_src_dir:\n",
    "    dst_dir = src_dir.replace('TEMPLATE', 'cochlearn_PND_v08inst_noise_TLAS_snr_neg10pos10')\n",
    "    fn_src_config = os.path.join(src_dir, 'config.json')\n",
    "    fn_src_arch = os.path.join(src_dir, 'brain_arch.json')\n",
    "    fn_dst_config = os.path.join(dst_dir, 'config.json')\n",
    "    fn_dst_arch = os.path.join(dst_dir, 'brain_arch.json')\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.mkdir(dst_dir)\n",
    "    \n",
    "    with open(fn_src_config, 'r') as f:\n",
    "        CONFIG = json.load(f)\n",
    "    \n",
    "    CONFIG['signal_rate'] = 32e3\n",
    "    CONFIG['BRAIN_PARAMS'].pop('save_pckl_path')\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_parsing_dict'].pop('nervegram_meanrates')\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_parsing_dict']['stimuli/signal_in_noise'] = {\n",
    "        \"dtype\": \"tf.float32\",\n",
    "        \"shape\": [4800]\n",
    "    }\n",
    "    CONFIG['ITERATOR_PARAMS']['feature_signal_path'] = 'stimuli/signal_in_noise'\n",
    "    with open(fn_dst_config, 'w') as f:\n",
    "        json.dump(CONFIG, f, indent=4, sort_keys=True)\n",
    "    \n",
    "    functions_parameter_handling.migrate_config_to_new_output_directory(\n",
    "        fn_dst_config,\n",
    "        dst_dir,\n",
    "        force_overwrite=True)\n",
    "    \n",
    "    with open(fn_src_arch, 'r') as f:\n",
    "        BRAIN_ARCH = json.load(f)\n",
    "    \n",
    "    BRAIN_ARCH = list_brain_arch_prepend + BRAIN_ARCH\n",
    "    with open(fn_dst_arch, 'w') as f:\n",
    "        json.dump(BRAIN_ARCH, f, indent=4, sort_keys=True)\n",
    "\n",
    "# print(json.dumps(CONFIG, indent=4, sort_keys=True))\n",
    "# print(json.dumps(BRAIN_ARCH, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting checkpoint 90000 (f0_label:accuracy=0.28781718015670776)\n",
      "Loading brain network config from /saved_models/arch_search_v02_topN/cochlearn/arch_0346/brain_arch.json\n",
      "[tfnnresample] interpreting `tensor_input.shape` as [batch, freq, time, channels]\n",
      "[tfnnresample] using up=5 rather than up=5 for nnresample_poly_filter\n",
      "[tfnnresample] using down=8 rather than down=8 for nnresample_poly_filter\n",
      "[tfnnresample] using cutoff frequency near 10000.0 Hz for anti-aliasing lowpass filter\n",
      "ADDING OPS TO CHECKPOINTS\n",
      "[<tf.Tensor 'brain_network/pool_1:0' shape=(?, 49, 104, 64) dtype=float32>, <tf.Tensor 'brain_network/pool_5:0' shape=(?, 7, 3, 512) dtype=float32>, <tf.Tensor 'brain_network/pool_6:0' shape=(?, 7, 3, 512) dtype=float32>, <tf.Tensor 'brain_network/pool_3:0' shape=(?, 20, 5, 256) dtype=float32>, <tf.Tensor 'brain_network/pool_4:0' shape=(?, 14, 4, 256) dtype=float32>, <tf.Tensor 'brain_network/pool_0:0' shape=(?, 98, 474, 32) dtype=float32>, <tf.Tensor 'brain_network/pool_2:0' shape=(?, 47, 10, 128) dtype=float32>]\n",
      "### Loading variables from specified checkpoint: /saved_models/arch_search_v02_topN/cochlearn/arch_0346/brain_model.ckpt-90000\n",
      "INFO:tensorflow:Restoring parameters from /saved_models/arch_search_v02_topN/cochlearn/arch_0346/brain_model.ckpt-90000\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import pitchnet_evaluate_best\n",
    "\n",
    "sys.path.append('ibmHearingAid/multi_gpu')\n",
    "import functions_graph_assembly as fga\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/python-packages/msutil')\n",
    "import util_figures\n",
    "\n",
    "\n",
    "output_directory_list = [\n",
    "#     ('/saved_models/models_sr20000/arch_0302/PND_v08_TLAS_snr_neg10pos10_AN_BW10eN1_IHC3000Hz_classification0', 'Natural'),\n",
    "#     ('/saved_models/models_sr20000/arch_0302/PND_v08_TLAS_snr_neg10pos10_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0', 'Natural (HPv00)'),\n",
    "#     ('/saved_models/models_sr20000/arch_0302/PND_synthetic_noise_UMNm_snr_neg10pos10_phase0_filter_signalHPv00_AN_BW10eN1_IHC3000Hz_classification0', 'Synthetic (HPv00)'),\n",
    "\n",
    "    ('/saved_models/arch_search_v02_topN/cochlearn/arch_0346', 'cochlearn/arch_0346'),\n",
    "#     ('/saved_models/arch_search_v02_topN/cochlearn_IHC4000Hz/arch_0302', 'cochlearn_IHC4000Hz/arch_0302'),\n",
    "#     ('/saved_models/arch_search_v02_topN/cochlearn/arch_0191', 'cochlearn/arch_0191'),\n",
    "#     ('/saved_models/arch_search_v02_topN/cochlearn_IHC4000Hz/arch_0191', 'cochlearn_IHC4000Hz/arch_0191'),\n",
    "]\n",
    "\n",
    "model_dict_list = []\n",
    "\n",
    "for (output_directory, model_name) in output_directory_list:\n",
    "    config_fn = os.path.join(output_directory, 'config.json')\n",
    "    validation_metrics_fn = os.path.join(output_directory, 'validation_metrics.json')\n",
    "    with open(config_fn) as f: CONFIG = json.load(f)\n",
    "    ckpt_num = pitchnet_evaluate_best.get_best_checkpoint_number(validation_metrics_fn,\n",
    "                                                                 metric_key='f0_label:accuracy',\n",
    "                                                                 maximize=True,\n",
    "                                                                 checkpoint_number_key='step')\n",
    "    \n",
    "    ITERATOR_PARAMS = CONFIG['ITERATOR_PARAMS']\n",
    "    N_CLASSES_DICT = CONFIG['N_CLASSES_DICT']\n",
    "    BRAIN_PARAMS = CONFIG['BRAIN_PARAMS']\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    shape = ITERATOR_PARAMS['feature_parsing_dict'][ITERATOR_PARAMS['feature_signal_path']]['shape']\n",
    "    batch_subbands = tf.placeholder(tf.float32, shape=[None] + shape)\n",
    "    if len(batch_subbands.shape) == 2:\n",
    "        batch_subbands = batch_subbands[:, tf.newaxis, :, tf.newaxis]\n",
    "    batch_out_dict, brain_container = fga.build_brain_graph(batch_subbands, N_CLASSES_DICT, **BRAIN_PARAMS)\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "    brain_var_scope = 'brain_network'\n",
    "    brain_ckpt_prefix_name = BRAIN_PARAMS.get('save_ckpt_path', 'brain_model.ckpt')\n",
    "    restore_model_path = os.path.join(output_directory, brain_ckpt_prefix_name + '-{}'.format(ckpt_num))\n",
    "    brain_globals = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=brain_var_scope)\n",
    "    brain_locals = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=brain_var_scope)\n",
    "    brain_variables =  brain_globals + brain_locals\n",
    "    saver_brain_net, out_ckpt_loc_brain_net, brain_net_ckpt = fga.build_saver(\n",
    "        sess, brain_variables, output_directory,\n",
    "        restore_model_path=restore_model_path,\n",
    "        ckpt_prefix_name=brain_ckpt_prefix_name)\n",
    "    \n",
    "    model_dict = {'model_name': model_name}\n",
    "#     for v in brain_variables:\n",
    "#         print(v)\n",
    "    tf_var = brain_variables[0] # conv0 filter kernels\n",
    "    tf_var_value = np.transpose(np.squeeze(sess.run(tf_var)))\n",
    "    tf_var_name = tf_var.name\n",
    "    model_dict['vars'] = {tf_var_name: tf_var_value}\n",
    "    model_dict_list.append(model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 32e3\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1,\n",
    "                       ncols=1,\n",
    "                       figsize=(12, 3),\n",
    "                       sharex=True,\n",
    "                       sharey=True)\n",
    "\n",
    "for model_dict in model_dict_list:    \n",
    "    model_name = model_dict['model_name']\n",
    "    kernels = model_dict['vars']['brain_network/coch_conv_0/kernel:0']\n",
    "    list_pxx = []\n",
    "    for idx in range(kernels.shape[0]):\n",
    "        fxx, pxx = util_stimuli.power_spectrum(kernels[idx], sr)\n",
    "        list_pxx.append(pxx)\n",
    "#         ax.plot(fxx, pxx, lw=1)\n",
    "    kernels_pxx = np.stack(list_pxx)\n",
    "    kernels_pxx_mean = np.mean(kernels_pxx, axis=0)\n",
    "    kernels_pxx_std = np.std(kernels_pxx, axis=0)\n",
    "    ax.plot(fxx, kernels_pxx_mean, label=model_name, lw=2)\n",
    "\n",
    "ax = util_figures.format_axes(ax,\n",
    "                                str_xlabel='Frequency (Hz)',\n",
    "                                str_ylabel='Mean power spectrum (dB)',\n",
    "                                fontsize_labels=12,\n",
    "                                fontsize_ticks=12,\n",
    "                                fontweight_labels=None,\n",
    "                                xscale='linear',\n",
    "                                yscale='linear',\n",
    "                                xlimits=None,\n",
    "                                ylimits=None,\n",
    "                                xticks=None,\n",
    "                                yticks=None,\n",
    "                                xticks_minor=None,\n",
    "                                yticks_minor=None,\n",
    "                                xticklabels=None,\n",
    "                                yticklabels=None,\n",
    "                                spines_to_hide=[],\n",
    "                                major_tick_params_kwargs_update={},\n",
    "                                minor_tick_params_kwargs_update={})\n",
    "ax.set_title('conv0 kernel mean power spectra', fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_var = brain_variables[0] # conv0 filter kernels\n",
    "tf_var_value = np.transpose(np.squeeze(sess.run(tf_var)))\n",
    "tf_var_name = tf_var.name\n",
    "\n",
    "sr = 32e3\n",
    "print(tf_var_name)\n",
    "\n",
    "N = tf_var_value.shape[0]\n",
    "\n",
    "NCOLS = 10\n",
    "NROWS = int(np.ceil(N / NCOLS))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=NROWS,\n",
    "                       ncols=NCOLS,\n",
    "                       figsize=(2.5*NCOLS, 2.5*NROWS),\n",
    "                       sharex=True,\n",
    "                       sharey=False)\n",
    "ax = ax.flatten()\n",
    "for idx in range(N):\n",
    "    x = tf_var_value[idx]\n",
    "    t = 1e3 * np.arange(0, len(x)) / sr\n",
    "    ax[idx].plot(t, x, 'k-', lw=0.5)\n",
    "    (str_xlabel, str_ylabel) = (None, None)\n",
    "    if idx % NCOLS == 0:\n",
    "        str_ylabel = 'Pa'\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        str_xlabel = 'Time (ms)'\n",
    "    ax[idx] = util_figures.format_axes(\n",
    "        ax[idx],\n",
    "        str_xlabel=str_xlabel,\n",
    "        str_ylabel=str_ylabel,\n",
    "        fontsize_labels=12,\n",
    "        fontsize_ticks=12,\n",
    "        fontweight_labels=None,\n",
    "        xscale='linear',\n",
    "        yscale='linear',\n",
    "        xlimits=None,\n",
    "        ylimits=None,\n",
    "        xticks=None,\n",
    "        yticks=None,\n",
    "        xticks_minor=None,\n",
    "        yticks_minor=None,\n",
    "        xticklabels=None,\n",
    "        yticklabels=None,\n",
    "        spines_to_hide=[],\n",
    "        major_tick_params_kwargs_update={},\n",
    "        minor_tick_params_kwargs_update={})\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=NROWS,\n",
    "                       ncols=NCOLS,\n",
    "                       figsize=(2.5*NCOLS, 2.5*NROWS),\n",
    "                       sharex=True,\n",
    "                       sharey=True)\n",
    "ax = ax.flatten()\n",
    "for idx in range(N):\n",
    "    x = tf_var_value[idx]\n",
    "    fxx, pxx = util_stimuli.power_spectrum(x, sr)\n",
    "    ax[idx].plot(fxx, pxx, 'k-', lw=0.5)\n",
    "    (str_xlabel, str_ylabel) = (None, None)\n",
    "    if idx % NCOLS == 0:\n",
    "        str_ylabel = 'PSD (dB/Hz SPL)'\n",
    "    if idx // NCOLS == NROWS - 1:\n",
    "        str_xlabel = 'Frequency (Hz)'\n",
    "    ax[idx] = util_figures.format_axes(\n",
    "        ax[idx],\n",
    "        str_xlabel=str_xlabel,\n",
    "        str_ylabel=str_ylabel,\n",
    "        fontsize_labels=12,\n",
    "        fontsize_ticks=12,\n",
    "        fontweight_labels=None,\n",
    "        xscale='linear',\n",
    "        yscale='linear',\n",
    "        xlimits=[10, 2e3],\n",
    "        ylimits=None,\n",
    "        xticks=None,\n",
    "        yticks=None,\n",
    "        xticks_minor=None,\n",
    "        yticks_minor=None,\n",
    "        xticklabels=None,\n",
    "        yticklabels=None,\n",
    "        spines_to_hide=[],\n",
    "        major_tick_params_kwargs_update={},\n",
    "        minor_tick_params_kwargs_update={})\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir_regex = '/saved_models/arch_search_v02_topN/cochlearn_PND_v08spch_noise_TLAS_snr_neg10pos10/arch_0???'\n",
    "model_dir_list = glob.glob(model_dir_regex)\n",
    "model_vars_dict = {}\n",
    "\n",
    "for model_dir in model_dir_list:\n",
    "    config_fn = os.path.join(model_dir, 'config.json')\n",
    "    validation_metrics_fn = os.path.join(model_dir, 'validation_metrics.json')\n",
    "    with open(config_fn) as f:\n",
    "        CONFIG = json.load(f)\n",
    "    ckpt_num = pitchnet_evaluate_best.get_best_checkpoint_number(validation_metrics_fn,\n",
    "                                                                 metric_key='f0_label:accuracy',\n",
    "                                                                 maximize=True,\n",
    "                                                                 checkpoint_number_key='step')\n",
    "    ITERATOR_PARAMS = CONFIG['ITERATOR_PARAMS']\n",
    "    N_CLASSES_DICT = CONFIG['N_CLASSES_DICT']\n",
    "    BRAIN_PARAMS = CONFIG['BRAIN_PARAMS']\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    shape = ITERATOR_PARAMS['feature_parsing_dict'][ITERATOR_PARAMS['feature_signal_path']]['shape']\n",
    "    batch_subbands = tf.placeholder(tf.float32, shape=[None] + shape)\n",
    "    if len(batch_subbands.shape) == 2:\n",
    "        batch_subbands = batch_subbands[:, tf.newaxis, :, tf.newaxis]\n",
    "    batch_out_dict, brain_container = fga.build_brain_graph(batch_subbands, N_CLASSES_DICT, **BRAIN_PARAMS)\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess = tf.Session()\n",
    "    sess.run(init_op)\n",
    "    brain_var_scope = 'brain_network'\n",
    "    brain_ckpt_prefix_name = BRAIN_PARAMS.get('save_ckpt_path', 'brain_model.ckpt')\n",
    "    restore_model_path = os.path.join(model_dir, brain_ckpt_prefix_name + '-{}'.format(ckpt_num))\n",
    "    brain_globals = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=brain_var_scope)\n",
    "    brain_locals = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=brain_var_scope)\n",
    "    brain_variables =  brain_globals + brain_locals\n",
    "    saver_brain_net, out_ckpt_loc_brain_net, brain_net_ckpt = fga.build_saver(\n",
    "        sess,\n",
    "        brain_variables,\n",
    "        model_dir,\n",
    "        restore_model_path=restore_model_path,\n",
    "        ckpt_prefix_name=brain_ckpt_prefix_name)\n",
    "    \n",
    "    tf_var = brain_variables[0] # conv0 filter kernels\n",
    "    tf_var_value = np.transpose(np.squeeze(sess.run(tf_var)))\n",
    "    tf_var_name = tf_var.name\n",
    "    model_vars_dict[model_dir] = tf_var_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))\n",
    "list_erb = util_stimuli.erbspace(125, 14e3, 100)\n",
    "ax.plot(list_erb, 'r.-', lw=2, ms=2, label='ERB (not learned)')\n",
    "\n",
    "list_list_cf = []\n",
    "for model_dir in model_dir_list:\n",
    "    kernels = model_vars_dict[model_dir]\n",
    "    list_cf = []\n",
    "\n",
    "    for itr_kernel in range(kernels.shape[0]):\n",
    "        fxx, pxx = util_stimuli.power_spectrum(kernels[itr_kernel], 32e3, dBSPL=False)\n",
    "        pxx_cumsum = np.cumsum(pxx)\n",
    "        pxx_cumsum = pxx_cumsum / pxx_cumsum[-1]\n",
    "        cf = fxx[pxx_cumsum >= 0.5][0]\n",
    "        list_cf.append(cf)\n",
    "        \n",
    "    ax.plot(np.sort(list_cf), '.-', lw=1, ms=1, label=os.path.basename(model_dir))\n",
    "    list_list_cf.append(np.sort(list_cf))\n",
    "\n",
    "list_list_cf = np.array(list_list_cf)\n",
    "yval, yerr = util_figures_psychophysics.combine_subjects(\n",
    "    list_list_cf, kwargs_bootstrap={})\n",
    "\n",
    "errorbar_kwargs = {\n",
    "    'yerr': yerr,\n",
    "    'fmt': 'none',\n",
    "    'ecolor': 'k',\n",
    "    'elinewidth': 0.5,\n",
    "    'capsize': 1.0,\n",
    "}\n",
    "ax.errorbar(np.arange(yval.shape[0]), yval, **errorbar_kwargs)\n",
    "ax.plot(np.arange(yval.shape[0]), yval, 'k.-', lw=2, ms=2, label='Mean Â± SEM')\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "ax = util_figures.format_axes(\n",
    "        ax,\n",
    "        str_xlabel='Filter index (sorted by CF)',\n",
    "        str_ylabel='Characteristic frequency (Hz)',\n",
    "        str_title='Spectral centroids of learned cochlear filters',\n",
    "        fontsize_labels=12,\n",
    "        fontsize_ticks=12,\n",
    "        fontweight_labels=None,\n",
    "        xscale='linear',\n",
    "        yscale='log',\n",
    "        xlimits=None,\n",
    "        ylimits=None,\n",
    "        xticks=None,\n",
    "        yticks=None,\n",
    "        xticks_minor=None,\n",
    "        yticks_minor=None,\n",
    "        xticklabels=None,\n",
    "        yticklabels=None,\n",
    "        spines_to_hide=[],\n",
    "        major_tick_params_kwargs_update={},\n",
    "        minor_tick_params_kwargs_update={})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tfnnresample] interpreting `tensor_input.shape` as [batch, freq, time, channels]\n",
      "[tfnnresample] using up=5 rather than up=5 for nnresample_poly_filter\n",
      "[tfnnresample] using down=8 rather than down=8 for nnresample_poly_filter\n",
      "[tfnnresample] using cutoff frequency near 10000.0 Hz for anti-aliasing lowpass filter\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360.086x116.598 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2021_05_07_pitchnet_paper_figures_v04/schematic_cnn_arch_0191_cochlearn.pdf\n"
     ]
    }
   ],
   "source": [
    "# CNN drawing on waveform input\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('ibmHearingAid/multi_gpu/')\n",
    "import functions_brain_network\n",
    "\n",
    "sys.path.append('/om2/user/msaddler/python-packages/msutil')\n",
    "import util_figures_cnn\n",
    "importlib.reload(util_figures_cnn)\n",
    "\n",
    "brain_arch_fn = '/saved_models/arch_search_v02_topN/cochlearn/arch_0191/brain_arch.json'\n",
    "\n",
    "layer_list = util_figures_cnn.process_cnn_layer_list(brain_arch_fn, input_shape=[1,1,4800,1])\n",
    "layer_list[1]['shape_activations'] = [100, 1600, 2]\n",
    "\n",
    "kwargs_polygon_kernel_update = {\n",
    "    'fc': [0, 1, 0],\n",
    "}\n",
    "\n",
    "sr = 32e3\n",
    "t = np.arange(0, 0.075, 1/sr)\n",
    "y = np.sin(2 * np.pi * 160 * t) + 0.25 * np.random.randn(t.shape[0])\n",
    "input_image = np.stack([y], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(1, 1))\n",
    "ax = util_figures_cnn.draw_cnn_from_layer_list(ax, layer_list,\n",
    "                                               deg_scale_x=60,\n",
    "                                               deg_skew_y=30,\n",
    "                                               scaling_w='log2',\n",
    "                                               scaling_h='log2',\n",
    "                                               scaling_n='log2',\n",
    "                                               range_h=[0.75, np.inf],\n",
    "                                               input_image=input_image,\n",
    "                                               kwargs_polygon_kernel_update=kwargs_polygon_kernel_update)\n",
    "\n",
    "[xb, yb, dxb, dyb] = ax.dataLim.bounds\n",
    "fig_factor = 6\n",
    "fig.set_size_inches(dxb/fig_factor, dyb/fig_factor)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save_dir = '/om2/user/msaddler/pitchnet/assets_psychophysics/figures/archive_2021_05_07_pitchnet_paper_figures_v04'\n",
    "# save_fn = os.path.join(save_dir, 'schematic_cnn_arch_0191_cochlearn.pdf')\n",
    "# fig.savefig(save_fn, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "# print(save_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
